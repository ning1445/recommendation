**基于注意力模型的多模态特征融合雷达知识推荐**

摘要

为了能够在数量庞大的雷达技术资料中快速准确地找到科研人员感兴趣的雷达知识信息并进行推荐，提出了一种基于注意力模型的文本多模态特征融合雷达知识推荐方法，学习高层次的雷达知识的多模态融合特征表示，进而实现雷达知识推荐。该方法主要包括数据预处理、多模态特征提取、多模态特征融合和雷达知识推荐 ４ 个阶段。

该方法的核心是通过注意力模型提升特征向量的性能，并且利用多模态特征之间优势互补的特性，提取知识的多模态特征，学习一种高层次的融合特征表示。分别提取雷达知识的词向量特征（ Ｗｏｒｄ２ｖｅｃ ）特征和词频 -逆文档率特征（ＴＦ－ＩＤＦ），并将雷达知识的 Ｗｏｒｄ２ｖｅｃ 特征输入到注意力模型中，得到 Ｗｏｒｄ２ｖｅｃ 特征经
过处理后的特征向量。为了实现多模态特征的融合，还设计了一种基于深度神经网络的多模态深度融合方法，结合分类交叉熵损失学习多模态特征的高阶融合特征。在雷达知识推荐阶段，采用所学习的雷达知识的融合特征计算相似度，将相似度最高的 Ｎ 个（ Ｔｏｐ － Ｎ ）推荐给用户。

 **基于注意力机制的雷达知识推荐模型**

![image-20221114104312965](https://github.com/ning1445/1/blob/main/11.16/1.jpg)

1. 雷达知识预处理

   (1)分词

   (2)去停用词

2. 注意力模型
   (１)将提取的雷达知识的 Ｗｏｒｄ２ｖｅｃ特征向量作为模型的输入层；

   (２)使用 ＬＳＴＭ 作为编码器，对输入的文本特征向量进行编码，获得文本的语义编码；
   (３)将语义编码输入到注意力机制层，放大重要特征的权重，得到整个网络的权重分配，充分挖掘文本的深层语义信息，得到表征能力更强的文本表示向量  ；
   (４)将注意力权重与潜在语义表示进行加权平均，得到最终的文本表示。

3. 多模态特征提取

   (1)提取并通过注意力模型处理雷达知识的 Ｗｏｒｄ２ｖｅｃ 特征。

   (2)提取雷达知识的基于词频的特征权重（ ＴＦ － ＩＤＦ ）算法特征

   (3)多模态特征串联

4. 多模态特征融合

   为了实现多模态特征融合，提出了一种基于深度神经网络的多模态特征融合方法，结合分类交叉熵损失学习多模态特征的高阶融合特征，具体的网络结构如图 ３ 所示。其中，多层神经网络负责融合多模态特征，ｓｏｆｔｍａｘ 层则用于度量分类损失，从而评价多模态融合特征的性能。网络的输入为雷达知识经过注意力模型处理之后的 Ｗｏｒｄ２ｖｅｃ特征和 ＴＦ － ＩＤＦ特征的串联特征。在网络的隐藏层中，使用２个全连接层，用于学习雷达知识的高阶特征，进行多模态特征融合。通过ｓｏｆｔｍａｘ层的输出计算分类损失，使损失函数最小化，提高融合后特征的分类精度。最终输出适用于目标任务的雷达知识的高阶融合特征。

   ![image-20221114105429313](https://github.com/ning1445/picture/blob/main/ddd/image-20221117152119502.png)

   损失函数由两部分组成。第一部分为交叉熵损失：

   ![image-20221114105631536](https://github.com/ning1445/picture/blob/main/ddd/image-20221114105631536.png)

   ｙｉ 为雷达知识的实际类别； ｐｉ 为 ｓｏｆｔｍａｘ 判别器输出的类别。

   除此之外，还考虑了不同模态之间的相似度保持，在损失函数中引入了拉普拉斯图正则化项：

   ![image-20221114105749384](https://github.com/ning1445/picture/blob/main/ddd/image-20221114105749384.png)

   L＝D - S， Ｓ 由标签信息计算得来，$S=yy^T $， Ｄ 是一个对角阵， Ｄ 的对角元为 Ｓ 的列和$\boldsymbol{D}=\operatorname{diag}\left(\sum_{j} S_{\mathrm{ij}}\right)$，ｔｒ 表示矩阵的迹运算。

   综上所述，深度神经网络的损失函数为

   ![image-20221114110117695](https://github.com/ning1445/picture/blob/main/ddd/image-20221114110117695.png)

   

5.  雷达知识推荐

对雷达知识进行余弦相似度计算，生成推荐列表

![image-20221114110311953](https://github.com/ning1445/picture/blob/main/ddd/image-20221114110311953.png)



**基于多模态图卷积网络的短视频推荐算法**

现有的推荐方法难以从短视频的模态层级进行用户兴趣建模，衡量短视频模态信息之间的差异性对用户偏好的影响。因此，本文提出结合短视频数据多模态的特点和图卷积网络(Graph Convolutional Network, GCN)的模型框架设计了一种基于多模态图卷积网络的短视频推荐算法，捕捉不同模态下用户的兴趣表达，进而为用户产生推荐。

本文首先根据用户对短视频的交互行为建立“用户-短视频”二部图(bipartite graph)，并依照短视频的模态种类不同分别构造对应的模态二部图；在传统 GCN 的邻域聚合方法上进行改进，提出了两级邻域聚合(Bi-level aggregation)策略以及基于注意力机制的邻域聚合器；根据 GCN中目标顶点的信息来源不同，设计阶层整合和外积整合两种整合层设计方法，实现目标顶点信息与邻域信息的整合；设计融合层实现用户以及短视频不同模态间信息的融合，输出用户和短视频的表征向量，体现短视频不同模态包含的信息差异对用户偏好的影响；最后通过输出层计算用户向量与短视频向量间的相似程度，为用户输出推荐。

多模态图卷积网络的短视频推荐算法，框架图。推荐模型主要由“用户-短视频”二部图、聚合层、整合层、融合层和输出层构成。

![image-20221114195012618](https://github.com/ning1445/picture/blob/main/ddd/image-20221114195012618.png)

#### **1.二部图**

根据短视频的视觉 (visual)、文本 (textual)和听觉 (acoustic) 三种模态类型不同，将交互行为二部图转化为特定模态下的二部图。每个二部图的拓扑结构相同，图上顶点的属性信息为对应的模态信息，不同模态图中顶点之间的距离远近代表相同顶点在不同模态情况下包含信息的差异。

#### **2.聚合层**

随着 GCN 深度 的增加，位于拓扑图中距离目标顶点跳数(hop)越多的高阶邻居如二阶、三阶邻居，其属性信息对于目标顶点表示学习的影响容易随着 GCN 层的传播而逐渐平滑直到出现梯度消失的现象，出现过平滑的问题。 

本文采用两级聚合策略，使用初态跳接得方法缓解过平滑问题。

聚合层由**邻域聚合**和**非线性处理**两部分组成，邻域聚合步骤将目标顶点的邻域信息通过聚合函数进行聚合，产生初步的邻域表示；

![image-20221114202327265](https://github.com/ning1445/picture/blob/main/ddd/image-20221114202327265.png)

将目标顶点 v 的一阶邻域信息和二阶邻域信息结合，输出目标顶点 的邻域表示向量

![image-20221114202436563](https://github.com/ning1445/picture/blob/main/ddd/image-20221114202436563.png)

非线性处理通过将目标顶点低阶特征与其邻域特征进行拼接，输入到单层神经网络中获取目标顶点的高阶特征：

![image-20221114202531011](https://github.com/ning1445/picture/blob/main/ddd/image-20221114202531011.png)

本文中，我们在传统的平均聚合以及最大池化聚合方法的基础上提出创新的**注意力聚合**方法：

**2.1注意力聚合方法**

通过逐顶点 (node-wise) 的方法，在目标顶点与其邻居顶点之间引入注意力分数，衡量目标顶点与邻居顶点的相似程度，从而根据邻居注意力分数大小不同，引导目标顶点进行表示学习。顶点 i 为顶点 v 的邻居，则两者的相似度定义为

![image-20221114203458586](https://github.com/ning1445/picture/blob/main/ddd/image-20221114203458586.png)

再通过函数LeakeyReLu 非线性转换和 Softmax 函数进行归一化得到顶点 v 和 i 之间的注意力分数 ：

![image-20221114203645614](https://github.com/ning1445/picture/blob/main/ddd/image-20221114203645614.png)

使用目标顶点与邻域之间的注意力分数对自身进行逐顶点聚合：

![image-20221114203706491](https://github.com/ning1445/picture/blob/main/ddd/image-20221114203706491.png)

为了使聚合结果更加健壮，我们将多头注意力机制

![image-20221114203917947](https://github.com/ning1445/picture/blob/main/ddd/image-20221114203917947.png)

#### 3.整合层

整合层在模型中的功能是将特定模态下目标顶点的自身属性信息与其高阶邻域信息进行整合.本文设计了阶层整合和外积整合两种整合方法用于顶点不同来源信息的整合：

![image-20221114204312979](https://github.com/ning1445/picture/blob/main/ddd/image-20221114204312979.png)

$ H_{m,v}$ 为顶点 v 在模态 m 下的表示向量; $X_{m,v}$为顶点在模态 包含的原始信息，可视为第零阶信息; $h_{v,id}$为在“用
户-短视频”二部图通过图嵌入方法得到的顶点 的嵌入向量，可以等效为顶点结构信息的表示向量。

**3.1阶层整合**

顶点的原始信息$X_{m,v}$ 和 ID 嵌入信息  $h_{v,id}$ 定义为顶点的低阶信息；顶点 v 经过聚合层的输出 $ h_{m,v}$ 定义为高阶信息。

==$ h_{m,v}$ 对应mmgcn中的结构信息 hm；$X_{m,v}$  对应mmgcn中的内在信息um； 对应mmgcn中的$h_{v,id}$模态连接uid==

首先将顶点原始信息和 ID 嵌入信息两者按元素进行拼接，再通过一层前馈神经网络

![image-20221114211007404](https://github.com/ning1445/picture/blob/main/ddd/image-20221114211007404.png)

随后将顶点的低阶表示与高阶信息 进行级联作为整合层的输出

![image-20221114211026340](https://github.com/ning1445/picture/blob/main/ddd/image-20221114211026340.png)

==mmgcn==

![image-20221114213908975](https://github.com/ning1445/picture/blob/main/ddd/image-20221114211324756.png)

**3.2外积整合**

外积整合的思路是将顶点在特定模态下信息分为**内容信息** (content information) 和**结构信息** (structural information) 两部分。$ H_{m,c}$ 为内容信息，由顶点 v 经过聚合层的输出 $ H_{m,v}$ 和其原始属性信息 $X_{m,v}$ 进行拼接得到；

![image-20221115100725594](https://github.com/ning1445/picture/blob/main/ddd/image-20221115100725594.png)

 $ H_{m,s}$=$h_{v,id}$为结构信息由顶点的 ID 嵌入信息构成，其包含了顶点在图中的拓扑结构信息。我们通过外积的方法对两类信息的向量进行交叉，最后经过一层前馈神经网络输出：

![image-20221114211324756](https://github.com/ning1445/picture/blob/main/ddd/image-20221114211324756.png)

#### 4.融合层和输出层

融合层将顶点（用户顶点和短视频顶点）的多个模态表示向量进行融合：

![image-20221114211512974](https://github.com/ning1445/picture/blob/main/ddd/image-20221114211512974.png)

定义“用户-短视频”二部图中与用户顶点 u 有直接相连边的短视频顶点 $i_p$ 为正样本；负样本定义为“用户-短视频”二部图中度数较高，且与目标用户顶点没有直连边的短视频顶点$i_n$ 

损失函数

![image-20221114212255989](https://github.com/ning1445/picture/blob/main/ddd/image-20221114212255989.png)



**Universal Graph Transformer Self-Attention Networks**

ABSTRACT

我们引入了一个基于变换器的GNN模型，名为UGformer，用于学习图表示。特别是，我们提出了两种UGformer变体，其中第一种变体是在每个输入节点的一组采样邻居上利用Transformer，而第二种变体则是在所有输入节点上利用Transformer。实验结果表明，第一个UGformer变型在归纳设置和无监督的传导设置中都达到了用于图分类的基准数据集的最新精度；而第二个UGformer变型获得了最先进的归纳文本分类精度。

1 INTRODUCTION

最近，图神经网络（GNN）成为一个重要的链，形成了学习节点和图的低维连续表示的第三个方向。一般来说，**GNN使用聚合函数通过变换和聚合其邻居的向量表示来更新每个节点的向量表示。**然后，GNN应用诸如简单和sum pooling之类的图级读出函数来获得图嵌入。基于GNN的方法为下游任务（如节点分类、图分类、知识图完成、漏洞检测和文本分类）的基准数据集提供了更快、实用的训练和最先进的结果。为了进一步提高性能，值得开发先进的GNN来更好地更新邻居节点的向量表示。目前，在自然语言处理中，Transformer的新应用得到了认可、并成功使用。受这一事实的启发，我们认为将Transformer用于GNN等新领域是一种新颖的做法，并提出了基于Transformer的GNN模型UGformer来学习图形表示。我们在本文中的主要贡献如下： 

•我们提出了一种基于Transformer的GNN模型，名为UGformer，用于学习图形表示。特别地，我们考虑两种模型变体：（i）在每个输入节点的一组采样邻居上利用Transformer，以及（ii）在所有输入节点上利用Transformer。

•无监督学习在工业和学术应用中都是必不可少的，扩展无监督GNN模型更适合解决类标签可用性有限的问题。因此，我们提出了一种无监督的直推学习学习方法来训练GNN。 

> 什么是半监督学习
>    所给的数据有的是有标签的，而有的是没有标签的。常见的两种半监督的学习方式是直推学习（Transductive learning）和归纳学习（Inductive learning）。 
>    **直推学习（Transductive learning）**：没有标记的数据是测试数据，这个时候可以用test的数据进行训练。这里需要注意，这里只是用了test数据中的feature而没有用label，所以并不是一种欺骗的方法。 
>    归纳学习（Inductive learning）：没有标签的数据不是测试集。 

•实验结果表明，第一个UGformer变体在归纳环境和无监督的直推环境中都获得了社交网络和生物信息学数据集的最新精度，用于图形分类；第二个UGformer变体在用于归纳文本分类的基准数据集上产生最先进的精度。 

> - **Transductive setting**：可以在所有拆分的数据集（训练、验证和测试集）中观察到输入的完整图。这种方式只是拆分（节点）对应标签。(1.数据集由一张图组成;  2.在所有数据集拆分中都可以观察到整个图，因此只需拆分标签;  3.仅适用于节点/边缘预测任务)
>
> - **Inductive setting**：将不同数据集划分之间的边删除，以得到多个图。(1.数据集由多个图组成;  2.个划分的集合只能观察数据集合内的图结构。任务本身需要推广到看不见的图;  3.适用于节点/边/图任务)
>
>   ![image-20221115155243461](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115155243461.png)

2 THE PROPOSED UGFORMER

2.1 Variant 1: Leveraging the transformer on a set of sampled neighbors for each node（在每个节点的一组采样邻居上利用transformer ）

![image-20221115103249325](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115103249325.png)

我们在2019年9月公布了第一个UGformer变体。这种变体也适用于大型图。给定一个输入图G，我们对每个 v∈V 的邻域集合进行均匀采样，然后将  Nv∪{v}  输入到UGformer学习过程中，如图1所示。注意，我们在每个训练批处理中为节点 v 采样不同的 Nv。我们利用 transformer 构建了多层叠加，其中权重矩阵在所有位置和时间步上的自注意函数和过渡函数中共享。具体来说，对于第 k 层，给定节点 v∈V，在每一步 t，我们引入一个基于 transformer 的函数来聚合所有节点u的向量表示 u∈ Nv∪{v} 如下： 

![image-20221115160334061](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115160334061.png)

其中$\mathbf{h}_{0, \mathrm{v}}^{(0)}=\mathbf{h}_{\mathrm{v}}^{(0)}$是 v 的特征向量；Trans（.）和ATT（.）分别表示MLP网络和自注意层。特别是，我们有： 

![image-20221115103938613](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115103938613.png)

其中 $V^{（k）}$是值投影权重矩阵；$\alpha_{u，u′}$ 是注意力权重，使用节点 u 和 u′ 之间的缩放点积上的softmax函数计算：

![image-20221115104142269](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115104142269.png)

其中Q（k）和k（k）分别是查询投影矩阵和键投影矩阵。

![image-20221115104243858](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115104243858.png)

在T步之后，我们将$h^{（k）}_{T，v}$馈送到（k+1）层，如下所示：

![image-20221115104334869](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115104334869.png)

如果我们不在所有位置和时间步长上共享自我注意和转移函数中的权重矩阵，T 成为每个UGformer层内的自我关注层的数量。 

2.2 Variant 2: Leveraging the transformer on all input nodes

![image-20221115105316435](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115105316435.png)

2021 5月，我们发布了第二个UGformer变体，当时我们的目标是将该转换器用于中小型图形。值得注意的是，自我注意层中所有位置之间的所有链接/交互构成了一个完整的网络。因此，如果我们仅将自注意机制应用于输入图 G 的所有节点，我们将忽略 G 的结构。为了克服这一限制，我们建议每个UGformer层由transformer 自关注网络组成，然后是GNN层，如GCN或 Gated GNNs。该模型变体将 transformer 与图结构相结合，以学习更好的图表示。从形式上讲，我们将图2所示的 UGformer 层定义为： 

![image-20221115105410477](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115105410477.png)

其中$H^{（0）}$是G中所有节点的特征矩阵，A是邻接矩阵。当T = 1时，方程7是关于方程1和2的。

3 DEMONSTRATION OF UGFORMER
3.1 UGformer Variant 2 for inductive text classification

我们展示了UGformer在归纳文本分类中的优势。首先，我们遵循[16，34]，通过将唯一单词表示为节点，并将单词之间的共现（在长度为3的固定大小滑动窗口内）表示为边，为每个文本文档构建图G。然后，我们使用我们的变型2，其中我们将Gated GNN用于等式8，因为Gated GNN层更适合我们的数据。之后，为了产生图嵌入eG，我们按照[18]构造图级读出函数： 

![image-20221115105709252](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115105709252.png)

其中 $h^{(K)}_v$ 为节点 v 在最后 K 层的向量表示;a是节点上的软注意机制。最后，我们还将eG输入到一个全连接层和一个softmax层，以执行文本分类任务。

3.3 UGformer Variant 1 for graph classification in an “unsupervised transductive” setting

我们提出了一种无监督的转导学习方法来训练GNN，以解决类标签可用性有限的问题。我们考虑每个节点 v 的最终嵌入ov，并使 ev 和 ov 之间的相似性高于 ev 和其他节点的最终嵌入之间的相似。目标是指导GNN识别和区分每个图中的子图结构信息，并记住图之间的结构差异，以产生更好的节点和图嵌入。我们的目标是最小化应用于节点 v 的采样softmax损失函数[8]，如下所示： 

![image-20221115110041164](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221115110041164.png)

其中V '是一个从{∪Vm}Mm=1采样的子集。节点嵌入ov也被学习为模型参数。然后对G中所有节点v的最终嵌入ov求和，得到嵌入eG的图。



**Structured Graph Convolutional Networks with Stochastic Masks for Recommender Systems**

http://yusanlin.com/files/papers/sigir21_structure.pdf

ABSTRACT

图卷积网络（GCN）在协同过滤方面功能强大。GCN的关键组成部分是探索邻域聚合机制，以提取用户和项目的高级表示。然而，现实世界中的用户项目图通常是不完整的，并且很嘈杂。如果GCN没有得到适当的正则化，聚集误导性的邻域信息可能会导致次优性能。此外，真实世界中的用户项目图通常是稀疏的和**低秩**的。这两个内在的图特性广泛应用于浅矩阵完成模型，但在图神经模型中研究较少。 

在这里，我们提出了结构化图卷积网络（SGCN），通过利用稀疏性和低秩的图结构特性来提高GCN的性能。为了实现稀疏性，我们将GCN的每一层附加一个可训练的随机二进制掩码，以修剪有噪声和不重要的边，从而得到一个干净和稀疏的图。为了保持其低秩性质，应用核范数正则化。我们通过求解随机二元优化问题，联合学习随机二元掩码和原始GCN的参数。进一步提出了一种无偏梯度估计器，以更好地反向传播二进制变量的梯度。

> 在协同过滤中，低秩体现在相似行为的用户对于商品有着相似的评分。

1 INTRODUCTION

图1说明了误导性信息是如何通过图中的噪声边传播的。这里我们考虑在用户-物品图中嵌入目标节点u1，用户u1和物品i4之间有一个噪声边，如图左子图所示。右边的子图是相应的树结构，节点u1是根。GCNs的核心思想是充分发现二部图中的高阶关系。因此，即使u1和i2之间没有显式连接，也可以通过路径u1←i3←u3←i2对节点i2的表示进行聚合，更新目标节点u1的表示。然而，误导性的消息，例如嵌入第一跳邻居i4或第二跳邻居u2，也可以通过有噪声的边缘u1−i4传递到目标节点u1，这可能会降低性能。随着gcs的深入，这些误导性的信息将继续传播并污染整个图。

![image-20221116153204569](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116153204569.png)

为此，我们认为在消息传递过程中删除不相关的邻居是至关重要的。否则，包括不太有用的消息将使模型训练复杂化，增加过度拟合的风险，甚至损害模型的有效性。关键的挑战是确定在训练阶段忽略不相关邻居的标准。幸运的是，真实世界的图通常是稀疏的和低秩的。稀疏意味着在消息传递期间，只有最重要的邻居才应该本地连接到目标节点；低秩约束表示整个图是全局结构化的，只有少数因素会影响用户的偏好。这两个内在图特性广泛用于线性矩阵完成模型，例如 lp 范数正则化或矩阵秩最小化，但在图神经模型中研究得很少。一种可能的方法是首先基于某种相似函数创建一个干净的 k 近邻图。而k近邻的表达能力受限于 k 的选择以及嵌入空间中的相似函数。 

**Present Work.** 

在这里，我们提出了一种结构化图卷积网络（SGCN），通过利用稀疏性和低秩的图结构特性来提高GCN的性能。为了实现稀疏性，我们在GCN的框架下，用随机二元掩码连接GCN的每一层，以修剪噪声和不重要的边缘。直观地说，随机二进制掩码（即，1被采样，0被丢弃）可以被视为图生成器，以支持GCN的每一层的高质量稀疏图。我们的动机有两方面：1）可以学习**以数据驱动的方式丢弃带有参数化mask的噪声边缘**。因此，稀疏消息传递策略不那么复杂，并且具有更好的泛化能力；2） **过拟合和过平滑是开发更深层次GCN的两个主要瓶颈**。这些问题可以通过使用我们的随机机制对子图进行采样来缓解。然而，由于离散样本的组合性质，直接训练随机二进制掩码是困难的。为了使它们可微，我们进一步通过概率重参数化将优化问题从离散空间重新表述为连续空间。进一步提出了一种无偏梯度估计器，以更好地反向传播二进制变量的梯度。受对抗性机器学习的启发，低秩约束也被施加到GCN的每一层的稀疏邻接矩阵上。这种正则化迫使图被全局结构化，这已被证明在防御对抗性攻击方面非常成功，更不用说防御推荐中的噪声了。我们进行了大量实验，以评估所提出的SGCN方法的有效性和鲁棒性。我们的贡献如下： 

•我们提出了SGCN，这是一种在GCN的消息传递阶段明确地修剪不相关邻居的方法，这在很大程度上减少了推荐系统中噪声的负面影响。 

•我们开发随机二进制掩码，目的是为GCN的每一层选择稀疏且高质量的子图。还施加了低秩约束以增强GCN的鲁棒性和泛化。 

•我们提出了一种用于随机二元优化的无偏梯度估计器，方法是将其转化为连续空间中的等效梯度。因此，我们可以共同学习随机二进制掩码和GCN的参数。 

2 RELATED WORK

Over-fitting and Over-smoothing

开发更深层次的GCN的两个主要障碍是过拟合和过平滑。过拟合来自于使用过参数化的GCN来拟合给定有限训练数据的分布的情况。相反，过平滑导致图节点的特征在增加卷积层的数量时逐渐收敛到相同的值。以上两个问题都可以通过在GCN中使用 dropout 技巧来缓解。例如，vanilla Dropout 随机 mask 权重矩阵中的元素，以减少过度拟合的影响。然而，Dropout并不能防止过度平滑，因为它不会改变图的邻接矩阵。DropNode 是一种面向节点的方法，它随机选择用于小批量训练的节点。DropEdge是一种面向边的方法，它从输入图中随机删除一定数量的边，就像数据增强器一样。Message
dropout 随机丢弃每个传播层中的传出消息以细化表示。DropoutNet 在训练期间应用输入 dropout，以解决推荐系统中的冷启动问题。尽管如此，这些丢弃技术通常会随机删除某一部分节点、边缘或特征，这可能导致性能次优。 

我们的随机二元掩码的机制与上述丢弃方法略有不同，但与图稀疏化的最新发展更为相关。我们引入了一种优化算法，这是随机抽样的一种替代方案，用于以数据驱动的方式确定要删除的边。 因此，最能保持所需属性（例如，稀疏和低秩）的稀疏图可以在**更好的鲁棒性和更好的泛化**方面使GCN受益。 

3 THE PROPOSED MODEL

在本节中，我们将详细介绍拟议的SGCN模型。我们的SGCN主要由三个部分组成：精心设计的GCN、随机二进制掩码和秩近似。最后，我们引入了用于模型优化的损失函数。 

3.1 Problem Formulation

在本文中，我们专注于从隐式反馈中学习用户的偏好。具体来说，点击、评论、购买等行为数据涉及一组用户U = {U}和项目 I = {I}，其中 $I^+_U$ 表示用户U之前交互过的项目，$I^−_U$ = I− $I^+_U$ 表示未观察到的项目。未被观察到的交互并不一定是负面的，用户可能只是没有意识到它们。

当把用户-物品交互看成二部图 G 时，我们可以构造一个隐式反馈矩阵R∈R|U |×|I |，其中|U|和|I|分别表示用户和物品的数量。，如果用户u与项目i有交互，Ru,i = 1，否则Ru,i = 0。可得其对应的二部图邻接矩阵A为:

![image-20221116155200544](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116155200544.png)

其中邻接矩阵A可以用作后面GCNs的输入图。我们的目标是推荐用户u∈U 感兴趣的 $I^−_U$ 项目的排序列表。

3.2 GCN for Recommendation

3.2.1 Embedding Layer.

遵循主流的图卷积推荐系统，我们通过嵌入查找表得到用户表示 u 和一个项目表示 i ： 

![image-20221116155353625](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116155353625.png)

其中 u 和 i 表示用户和项目的id ;eu∈Rd 和 ei∈Rd 分别为用户 u 和物品 i 的嵌入，d为嵌入大小。这些嵌入被期望记住项目和用户的初始特征。接下来我们介绍两个最先进的基于 gcn 的推荐模型。

3.2.2 NGCF. 

遵循标准GCN，NGCF利用用户项二分图执行嵌入传播和特征变换，如下所示： 

![image-20221116155930241](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116155930241.png)

式中 e(k)u 和 e(k)i，初始化如式(2)中 e(0)u = eu和 e(0) i = ei，分别表示GCN第 k 层用户u和物品 i 的精确表示;    $\sigma$(·)为非线性激活函数，⊙为元素智能乘积;    W1和W2是可训练权重矩阵;    Nu表示与用户u直接交互的项目集合，Ni表示与项目i连接的用户集合。随着叠加更多卷积层，模型能够探索用户与项目之间的高阶协同信号。

3.2.3 LightGCN. 

几项研究指出，更简单、有时是线性的GCN对于表征学习非常有效。最近，LightGCN旨在简化NGCF的设计，使其更简洁，便于推荐。 

与NGCF相比，LightGCN采用加权和聚合器，并放弃使用特征变换和非线性激活。因此，等式（3）中的传播可以简化为： 

![image-20221116160303985](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116160303985.png)

上面的等式可以用紧凑矩阵形式重写。设第0层嵌入矩阵为$\mathbf{E}^{(0)} \in \mathbb{R}^{(|\mathcal{U}|+|I|) \times d}$, 其从等式（2）收集用户和项目的所有嵌入。然后，我们可以得到等式（4）的等价矩阵形式： 

![image-20221116160435033](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116160435033.png)

其中$\mathbf{A} \in \mathbb{R}^{(|\mathcal{U}|+|I|) \times(|\mathcal{U}|+|I|)}$；D是对应的对角度矩阵，其中每个元素 Di,i 表示矩阵A的第 i 行非零的个数。 

3.2.4 Model Optimization for NGCF and LightGCN.

通过传播 K 层，GCNs 获得 K + 1 个嵌入来表示一个用户(e(0)u，…， e(K)u)和一个项(e(0)i，…， e(K)i)。使用一个聚合函数来获得最终的表示形式:

![image-20221116160804617](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116160804617.png)

NGCF通过级联实现AGG（·），而LightGCN使用加权和。内积用于预测偏好得分： 

![image-20221116160834025](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116160834025.png)

两种方法都使用贝叶斯个性化排序（BPR）损失来优化模型参数，即最小化： 

![image-20221116160850706](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116160850706.png)

其中$O=\left\{(u, i, j) \mid u \in \mathcal{U} \wedge i \in I_{u}^{+} \wedge j \in I_{u}^{-}\right\}$为成对训练数据; $\sigma$(·)为sigmoid函数;Θ表示模型参数，a控制L2范数以防止过拟合。

3.2.5 Limitations.

尽管NGCF和LightGCN取得了成功，但我们认为它们不足以解决二分图中的噪声。例如，LightGCN完全依赖于邻接矩阵A来细化等式（5）中的用户和项目的表示。然而，如第1节所述，矩阵A可能包含噪声边缘，这些误导性信息随着LightGCN的深入而继续传播。当图噪声信号包含低频分量时，情况变得更糟。因此，GCN存在过度适应噪声的高风险。 

另一方面，vanilla Dropout随机屏蔽了权重矩阵中的元素（例如，等式（3）中的W1和W2），这可能具有有限的防止噪声的能力，因为它不会对相邻矩阵A进行任何更改。然而，这削弱了在训练阶段应保留或删除哪条边的可解释性和理解性（详见第4.3节）。为了应对这一挑战，我们提出了一种简单而有效的数据驱动原理，即随机采样的替代方案，通过使用随机二进制掩码来屏蔽边。 

3.3 Stochastic Binary Masks

3.3.1 Graph Sparsification. 

![image-20221116161610908](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116161610908.png)

为了滤除噪声，我们将GCN的每一层附加一个随机二进制掩码，以在训练GCN参数的同时修剪不重要的边缘。整个网络架构如图2所示。形式上，对于等式（5）中的每个卷积层，引入二元矩阵Z(k)∈{0,1}，其中 $Z^{(k)}_{u,v}$ 表示节点 u 和节点 v 之间的边是否包含在第 k 层中。与Eq.(5)中固定的邻接矩阵不同，第 k 层的输入图邻接矩阵为:



![image-20221116161909809](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116161909809.png)

⊙ 表示元素乘积。直观地说，随机二进制掩码Z(k) （即，1被采样并且0被丢弃）可以被视为图生成器，以便支持GCN的每一层的高质量稀疏图。稀疏图在训练期间支持邻居聚集的子集，而不是完全聚集，从而避免了GCN深入时的过平滑。这种图稀疏化的想法并不新鲜。事实上，它的原始目标是在保留输入图的基本信息的同时去除不必要的边以进行图压缩，最近在深度图模型中重新讨论了这一点。 

为了鼓励A(k)的稀疏性，使用L0正则化器显式地惩罚Z(k)的非零项个数，通过最小化:

![image-20221116162048449](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116162048449.png)

其中∥·∥0表示 L0 范数，可以使不重要的边完全为零。I[c] 是一个指示函数，如果条件c成立，则该函数为1，否则为0。然而，由于二元掩码Z(k)的$2^{| G |}$可能状态的不可微性、离散性和组合性，这种惩罚下的优化在计算上是难以处理的。 为了应对这一挑战，我们将这些离散变量重新参数化为基础连续变量的确定性变换，然后应用反向采样来产生低方差和无偏梯度。接下来，我们将介绍一种有效的算法，以更好地通过随机二进制层反向传播梯度。 

3.3.2 Reparameterization and Gradients.

由于Z(k)与原始GCNs(如NGCF或LightGCN)共同优化，我们将Eq.(6)和Eq.(8)合并为一个统一目标:

![image-20221116162454967](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116162454967.png)

其中 $\beta$ 控制图的稀疏性。因此，式(9)涉及到随机梯度估计，需要对$2^{| G |}$二元序列进行边缘化。为此，我们认为每个$Z^{(k)}_{u,v}$服从参数$Π^{(k)}_{u,v}$∈[0,1]的伯努利分布，使$Z^{(k)}_{u,v}$∼Bern($Π^{(k)}_{u,v}$)。式(9)可以重新表述为

![image-20221116163154890](C:\Users\an\AppData\Roaming\Typora\typora-user-images\image-20221116163154890.png)

其中E为期望，而Eq.(10)中的目标 $\hat L$ 实际上是Eq.(9)中目标 L 在参数 $Π^{(k)} $上的变分上界。第二项对于新的参数$Π^{(k)} $是可微的，而第一项由于$Z^{(k)}$的离散性质仍然是有问题的。

未看完
