Structured Graph Convolutional Networks with Stochastic Masks for Recommender Systems**

http://yusanlin.com/files/papers/sigir21_structure.pdf

ABSTRACT

图卷积网络（GCN）在协同过滤方面功能强大。GCN的关键组成部分是探索邻域聚合机制，以提取用户和项目的高级表示。然而，现实世界中的用户项目图通常是不完整的，并且很嘈杂。如果GCN没有得到适当的正则化，聚集误导性的邻域信息可能会导致次优性能。此外，真实世界中的用户项目图通常是稀疏的和**低秩**的。这两个内在的图特性在图神经模型中研究较少。 

在这里，我们提出了结构化图卷积网络（SGCN），**通过利用稀疏性和低秩的图结构特性来提高GCN的性能**。为了实现稀疏性，我们将GCN的每一层附加一个可训练的随机二进制掩码，以修剪有噪声和不重要的边，从而得到一个干净和稀疏的图。为了保持其低秩性质，应用核范数正则化。我们通过求解随机二元优化问题，联合学习随机二进制掩码和原始GCN的参数。进一步提出了一种无偏梯度估计器，以更好地反向传播二进制变量的梯度。

> 在协同过滤中，低秩体现在相似行为的用户对于商品有着相似的评分。

1 INTRODUCTION

个性化推荐系统已广泛部署在许多在线服务中，以满足用户的兴趣[47]。最突出的技术之一是协同过滤，它考虑用户的历史交互，并假设过去有相似偏好的用户在未来会做出类似的决定。因子分解机器通过使用用户嵌入和项目嵌入的内积作为偏好得分而取得了巨大成功[23]。然而，由于缺乏学习高阶用户项目特征交互的策略，他们的推荐性能不令人满意[5，15，18，26，27，51]。因此，深度学习技术已经开始主导推荐系统的格局[48]。 

最近，图卷积网络（GCN）在图结构数据的表示学习中变得越来越强大[16，22，44]。GCN在输入图上使用消息传递机制，可以概括为三个步骤：1）用节点的初始属性或结构特征（如节点度）初始化节点表示；2） 通过递归聚合和变换其邻居的表示来更新每个节点的表示；3） 根据下游任务的要求，读取单个节点或整个图形的最终表示。通过将用户-项目交互视为一个二分图，研究人员试图采用GCN进行推荐，因为其理论优雅且性能良好[11，17，30，42，47]。例如，PinSage[47]将有效的随机游走和图卷积结合起来生成项目嵌入。NGCF[42]提出了一种嵌入传播层来研究二部图中的高阶连通性。LightGCN[17]简化了GCN的设计，使其更简洁，便于推荐。 

> 在无向图中，某个节点的度等于与该节点直接相连节点的数量；在有向图中还需要考虑入度和出度。

尽管已经取得了令人鼓舞的性能，但由于其递归消息传递模式，GCN仍然容易受到输入图质量的影响[7，52]。不幸的是，现实世界中的用户项目图通常很嘈杂。这对于隐式行为尤其如此，因为它们不一定与用户偏好一致[37]。如果GCN没有得到适当的正则化，聚集误导性的邻域信息可能会导致次优性能。我们使用下面的例子来进一步解释上面提到的问题。 

图1说明了误导性信息是如何通过图中的噪声边传播的。这里我们考虑在用户-物品图中嵌入目标节点u1，用户u1和物品i4之间有一个噪声边，如图左子图所示。右边的子图是相应的树结构，节点u1是根。GCNs的核心思想是充分发现二部图中的高阶关系。因此，即使u1和i2之间没有显式连接，也可以通过路径u1←i3←u3←i2对节点i2的表示进行聚合，更新目标节点u1的表示。然而，误导性的信息，例如嵌入第一跳邻居i4或第二跳邻居u2，也可以通过有噪声的边缘u1−i4传递到目标节点u1，这可能会降低性能。随着GCN的深入，这些误导性的信息将继续传播并污染整个图。

![image-20221121150430648](https://gitee.com/ning13445/picture/raw/master/1/image-20221121150430648.png)

为此，我们认为在消息传递过程中删除不相关的邻居是至关重要的。否则，包括不太有用的信息将使模型训练复杂化，增加过度拟合的风险，甚至损害模型的有效性。关键的挑战是确定在训练阶段忽略不相关邻居的标准。幸运的是，真实世界的图通常是稀疏的和低秩的[12]。**稀疏意味着在消息传递期间，只有最重要的邻居才应该本地连接到目标节点；低秩约束表示整个图是全局结构化的，只有少数因素会影响用户的偏好。这两个内在图特性广泛用于线性矩阵完成模型**[4，23，32]，例如。lp 范数正则化或矩阵秩最小化，但在图神经模型中研究得很少。一种可能的方法是首先根据某种相似性函数创建一个干净的 k-近邻图。这是在LLE[36]和Isomap[39]等阴影图模型中常用的策略，最近在深度图模型[49]中也被重新审视。然而，k-近邻的表达能力受限于k的选择以及嵌入空间中的相似性函数。