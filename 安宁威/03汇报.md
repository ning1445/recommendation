### 05.24

将引用论文和共现次数>=k的论文节点特征先采用图注意力聚合到目标item节点上，再进行改进的图注意力机制更新user和item信息。效果有提升。

现在评价指标的值和之前找的论文中的结果差距较大，不好直接进行比较。另外Precition和Recall的值较低，可能有问题，还需要检查一下。

还有，现在将引用论文和共现次数>=k的论文节点特征聚合到目标item节点上采用的是普通的图注意力，可以尝试改成论文Graph-Refined Convolutional Network for Multimedia Recommendation with Implicit Feedback中的改进的图注意力机制试一下。

|                                       | Precition  | Recall     | NDCG       |
| ------------------------------------- | ---------- | ---------- | ---------- |
| 只使用user和item信息                  | 0.0783     | 0.1225     | 0.2565     |
| 加入引用信息                          | 0.0810     | 0.1275     | 0.2650     |
| 加入sim最高的9个                      | 0.0796     | 0.1263     | 0.2648     |
| 加入共现次数>=3论文信息               | 0.0827     | 0.1298     | **0.2676** |
| 加入共现次数>=4论文信息               | 0.0818     | **0.1304** | 0.2672     |
| 加入共现次数>=5论文信息               | 0.0806     | 0.1266     | 0.2669     |
| 同时加入引用信息和共现次数>=3论文信息 | 0.0830     | 0.1315     | 0.2715     |
| 同时加入引用信息和共现次数>=4论文信息 | **0.0834** | **0.1338** | **0.2731** |
| 同时加入引用信息和共现次数>=5论文信息 | 0.0818     | 0.1313     | 0.2672     |

## 05.28

把共现次数>=4论文看做困难负样本，因为任意两个item如果和多个用户都同时有交互，那么可以认为这两个item有一定的相关性，而在其它用户处只和其中一个item进行交互，那么可以认为对于这个用户来说，另一个item是他的困难负样本。在选取负样本时提高选取他们的比例，评价指标有所提升。

因为修改后的代码中的 Recall 和 Precition较低，所以我尝试将 LATTICE 论文代码中的评价指标部分换到GRCN代码中，结果有点问题，评价指标全都很低，正在修改代码。



top10推荐

|                                                              | Precition  | Recall     | NDCG       |
| ------------------------------------------------------------ | ---------- | ---------- | ---------- |
| 只使用user和item信息((GRCN源代码)，20年论文                  | 0.0783     | 0.1225     | 0.2565     |
| （GRCN修改）同时加入引用信息和共现次数>=4论文信息            | **0.0834** | **0.1338** | **0.2731** |
| （LATTICE代码）21年论文                                      | 0.11146    | 0.20104    | 0.26485    |
| （GRCN修改）加入引用信息和共现次数>=4论文信息，加入困难负样本 | 0.0905     | 0.1465     | 0.2916     |



LATTICE代码top[10,20,30,40,50]推荐结果

recall=[0.20104, 0.28290,0.34269, 0.38250, 0.41706], precision=[0.11146, 0.08390,0.07004, 0.05948, 0.05215], hit=[0.56422, 0.67429,0.74095, 0.77842, 0.80850], ndcg=[0.26485, 0.31561,0.34973, 0.37242, 0.39093]



## 05.31

代码本身没有问题，现在准备再代码上面加入其它评价指标，查看效果。

或者可能是改进的图注意力模型本身的原因，可以尝试换成其它模型。

## 06.04
加了一些其他的评价指标，代码还没有跑完。



## 06.07

其他的评价指标也比21年论文要低。我在想可不可以用我修改后的代码在多模态数据集上运行，然后小论文写多模态推荐。20年论文源代码和21年论文代码在多模态的数据集上的运行结果上面各个评价指标都是21年论文LATTICE比20年论文GRCN要高一些。

![image-20230607221410463](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230607221410463.png)

![image-20230607221401537](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230607221401537.png)



| 加入其他指标          | Precition  | Recall     | NDCG       | mrr        | f1        | map        |
| --------------------- | ---------- | ---------- | ---------- | ---------- | --------- | ---------- |
| （GRCN修改）20年论文  | 0.0904     | 0.1480     | 0.2927     | 01453      | 0.0938    | 01392      |
| LATTICE代码）21年论文 | 0.11138534 | 0.19995836 | 0.26365863 | 0.19906323 | 0.1207135 | 0.18319896 |
|                       |            |            |            |            |           |            |
|                       |            |            |            |            |           |            |

## 06.14

20年论文源代码GRCN运行多模态数据集，我运行的数据集和GRCN作者运行的数据集数据有些差别，但都是tiktok数据集。结果差别较大。

|                    | Precition | Recall | NDCG   |
| ------------------ | --------- | ------ | ------ |
| GRCN源代码（2020） | 0.0373    | 0.0571 | 0.1527 |
| GRCN原论文结果     | 0.0195    | 0.1048 | 0.0938 |
|                    |           |        |        |

## 06.17

一些中文期刊论文结果

|                                                              | HR     | NDCG   | Precition | MRR   | Ｒecall | F1-score | AUC     | ILS    | HD     |
| ------------------------------------------------------------ | ------ | ------ | --------- | ----- | ------- | -------- | ------- | ------ | ------ |
| 结合文本与隐反馈信息的学术论文推                                                  荐方法2022（小型微型计算机系统） | 0.774  | 0.484  |           |       |         |          |         |        |        |
| TAGAN：一种融合细粒度语义特征的                                                     学术论文对抗推荐算法2021（电信科学） | 0.46   | 0.33   |           |       |         |          |         |        |        |
| 一种基于标题与摘要语义的                                                                 学术论文推荐方法2021（数字技术与应用） |        | 0.161  | 0.011     | 0.010 |         |          |         |        |        |
| 一种融合用户显隐式阅读偏好的                                                           论文推荐模型2022（计算机应用与软件） |        |        | 0.459     |       | 0． 487 | 0． 432  | 0． 703 |        |        |
| 卷积融合文本和异质信息网络的<br/>学术论文推荐算法2022（计算机应用与软件） | 60．31 | 40．93 |           |       |         |          |         | 20．31 | 99．63 |



结合文本与隐反馈信息的学术论文推荐方法:随机选取  99 个之前没有交互的论文作为测试负样本

 TAGAN：一种融合细粒度语义特征的学术论文对抗推荐算法2021:80% 的交互数据作为训练集，其余 20%
的交互数据为测试集

一种基于标题与摘要语义的学术论文推荐方法:没有说明数据集划分方法。

一种融合用户显隐式阅读偏好的论文推荐模型:     7 ∶ 2 ∶ 1比例将数据集划分成训练集、验证集和测试集

 卷积融合文本和异质信息网络的学术论文推荐算法:  999 个之前没有交互的论文作为测试负样本

## 06.21

运行了一下多模态的几个代码，使用tiktok数据集

|               | Precition | Recall | NDCG   |
| ------------- | --------- | ------ | ------ |
| mmgcn（2019） | 0.0241    | 0.0345 | 0.0328 |
| mgat（2020）  | 0.0296    | 0.0446 | 0.0412 |
| GRCN（2020)   | 0.0370    | 0.0568 | 0.1521 |

## 06.24

在tiktok数据集使用单个模态，使用修改后的GRCN代码（加入item信息）

|             | Precition | Recall | NDCG   |
| ----------- | --------- | ------ | ------ |
| GRCN（2020) | 0.0350    | 0.0521 | 0.1445 |
| 修改GRCN    | 0.0368    | 0.0551 | 0.1516 |
|             |           |        |        |

## 07.02



一些中文期刊的对比实验选择，都是选取的比较老的实验作为对比。

|                                                              | 对比实验          |                          |                       |                   |                  |
| ------------------------------------------------------------ | ----------------- | ------------------------ | --------------------- | ----------------- | ---------------- |
| 结合文本与隐反馈信息的学术论文推荐方法2022（小型微型计算机系统） | NCF        2017   | DeepCoNN            2017 | DeepCoNN++       2018 |                   |                  |
| TAGAN：一种融合细粒度语义特征的 学术论文对抗推荐算法2021（电信科学） | MF-BPR     2009   | ItemPop    2010          | ConvMF     2016       | IRGAN        2017 |                  |
| 一种基于标题与摘要语义的 学术论文推荐方法2021（数字技术与应用） | BPR   2009        | CDL  2015                | ConvMF  2016          |                   |                  |
| 一种融合用户显隐式阅读偏好的论文推荐模型2022（计算机应用与软件） | BPＲMF    2009    | NeuMF     2017           | CML         2017      | KGAT       2019   | DKN        2018  |
| 卷积融合文本和异质信息网络的<br/>学术论文推荐算法2022（计算机应用与软件） | MF-BPＲ      2009 | CDL              2015    | HE-Ｒec     2016      | Neu-MF      2016  | CONV-NCF    2020 |



**论文推荐的数据集中，没有用户对应的社交数据，有些地方没办法实现**

Social4Rec: Distilling User Preference from Social Graph for Video Recommendation in Tencent

#### PRELIMINARY

A. Self-organizing Neural Network

给定一个用户嵌入，SoNN将他/她分配到如下的兴趣组j

![image-20230627111910071](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230627111910071.png)

Xu 是用户u的嵌入,Wj 就是自组织神经网络的可训练的权重。

![image-20230627111938984](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230627111938984.png)

用户嵌入Xu通过基于最小化后续损失函数的反向传播进行更新

B. Recommendation

用户u和物品t之间的相关分数计算如下

![image-20230627112015599](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230627112015599.png)

#### METHODOLOGY

##### A. Cluster-Calibrator-Merge Module

Embedding Layer.

用户嵌入通过下式得到

![image-20230627112125598](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230627112125598.png)

Cluster Layer.

在给定用户嵌入的情况下，通过优化Eq. 1更新组分配f(·)，通过优化Eq. 2更新用户嵌入Xu。每次迭代交替更新两个步骤。经过多次迭代，过程收敛，各兴趣组和用户得到稳定的嵌入。学习到的组分配f(·)作为下一层的指导。

Calibrator Layer.

为了缓解稀疏关系挑战在真实社交图中引入的差异，我们设计了一种受mask 语言模型(mask Language Model, MLM)[25]启发的新型校准器。

同时，借鉴蒸馏技术[26]，[27]，我们利用章节III-A中训练良好的在所有关系类型的用户子集U上训练的f(·)作为教师模型，然后在具有稀疏关系的社交图上训练出一个更鲁棒的学生模型k(·)。

特别是，教师模型的输入嵌入Xu被污染为学生模型的输入嵌入![image-20230628111328000](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230628111328000.png)，其中Eq. 4中的一小部分关系被随机替换为零。校准器的目标是模拟教师f(·)和学生k(·)之间的预测分布，其中损失可以通过KL散度测量为

![image-20230628111356731](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230628111356731.png)

Merge Layer.

在兴趣组的数量和兴趣组内用户的兴趣一致性之间存在权衡。为了确保模型能够准确地从社交图中建模兴趣特征，我们优先考虑保持兴趣组内的兴趣一致性。因此，一些兴趣组的用户很少，这也是需要避免的。为了解决这个问题，我们采用k-means聚类方案将包含很少用户的兴趣组与最近的兴趣组合并

通过以上模块，CCM具备了在社交图中对用户进行稀疏关系建模，并将用户准确划分为多个兴趣组的能力。

##### B. Social Enhanced Recommendation Module

在获取用户对应的兴趣群组之后，我们首先通过关系类型将目标用户u的邻居整合到其兴趣群组中，可以表示为：

![image-20230627112324112](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230627112324112.png)

其中![image-20230628112310118](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230628112310118.png)为与用户u的关系类型为 $l$ 的邻居。直观地看，不同的用户与不同关系类型的邻居的兴趣一致性是不同的。为了解决社交图中的琐碎关系挑战，我们采用注意机制最终确定用户u的整体兴趣感知社会表征如下

![image-20230627112338959](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230627112338959.png)

 αul注意力分数计算如下

![image-20230628112500885](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230628112500885.png)

Logits βu，t计算为

![image-20230628112630924](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230628112630924.png)

在式9中，q(·)和Fu分别是用户u的全连接层和基于行为的嵌入。以更准确、更容易进行兴趣学习的行为特征为指导，可以得到一个可靠的社会表征Hu，用于兴趣特征的补充。

在兴趣感知社会表征Hu的情况下，Eq. 3可以通过如下的社交图G得到增强

![image-20230627112427304](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230627112427304.png)

## 07.05

数据集处理：删除评分为1，2，3，4的数据，然后删除出现次数少于5的item，再删除交互次数少于20的数据。最后按照8：1：1划分数据集。

文本模态

MAX Precition:0.0127 Recall:0.0342 NDCG:0.0576

图像模态

MAX Precition:0.0125 Recall:0.0346 NDCG:0.0569-



## 07.24

论文推荐不同编码器结果

2020GRCN源代码，不同编码器结果

|                               | Precition | Recall  | NDCG    |      |      |
| ----------------------------- | --------- | ------- | ------- | ---- | ---- |
| GRCN—bert                     | 0.1183    | 0.1922  | 0.3511  |      |      |
| GRCN—dm                       | 0.0810    | 0.1269  | 0.2604  |      |      |
| GGRCN—dbow                    | 0.1215    | 0.1966  | 0.3556  |      |      |
| 2021年论文LATTICE（协同过滤） | 0.11176   | 0.20141 | 0.26492 |      |      |
| GRCN—bert修改后               | 0.1211    | 0.1982  | 0.3572  |      |      |
| GRCN—dm修改后                 | 0.1186    | 0.1943  | 0.3532  |      |      |





2022年ECCV论文  Lightweight Attentional Feature Fusion: A NewBaseline for Text-to-Video Retrieval

本文主要讨论了文本检索视频任务中的特征融合]问题。提出了一种基于轻量但是有效的特征融合模块LAFF构建的跨模态双端融合架构。

![image-20230724211534047](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230724211534047.png)

![image-20230724212327876](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230724212327876.png)



目前在使用不同编码器获取特征向量。已经得到bert，fasttext，doc2vec中的dm，dbow特征向量。正在获取glove，elmo特征向量。