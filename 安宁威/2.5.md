目前主要问题是之前找的代码测试部分还有一个bug没有解决。现在在看lightgcn的代码，此代码已经运行成功，还有一部分没有看完，看完之后再尝试对之前代码进行修改。

![image-20230205205406929](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230205205406929.png)

基于 BERT-GAT 的科技论文审稿专家推荐算法研究

摘要

随着科技论文投稿数量的快速增长，对评审推荐算法的改进势在必行。确保送审论文的高质量、送审论文与专家的精准匹配是改进评审推荐算法亟需解决的问题。文章提出融合语义信息的图注意力网络（BERT-graph attention networks，BERT-GAT）算法解决论文推荐审稿专家问题，首先基于专家已发表论文，提取关键词形成专家的研究方向并构建二分图，然后使用 BERT 提取论文摘要或标题的语义信息，并基于二分图构建 GAT 模型，最后将论文的语义信息和 GAT 融
合得到 BERT-GAT 模型。对比其他推荐算法，BERT-GAT 算法在各评价指标上取得了较好的结果，表明了该算法的有效性。

1　BERT-GAT 模型构建

融入 BERT 的图注意力网络模型架构如图 1 所示

![image-20230131211242992](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131211242992.png)

1.1 问题说明
令审稿专家集合为 U={u 1,u2 ,…,u M }，M 为专家个数，论文文本数据分为专家发表的论文I1 和科技论文 I 2 ，I 1 用于训练模型，从专家发表的论文中提取出关键词 K={k 1,k2 ,…,k n }，n 为关键词个数，用于确定专家的科研方向，并根据专家的科研方向为科技论文推荐审稿专家。

1.2 二分图数据构建

因为需要把科技论文推荐给合适的审稿专家，这些审稿专家的科研方向应与科技论文的科研方向相似，所以需要挖掘科研方向相似的审稿专家，而GAT 可以很好的挖掘相似数据。构建关键词 – 关键词二分图用于聚合近邻节点信息，通过高阶 GAT 可以获得与关键词远距离的其他关键词信息，专家 –关键词二分图用于根据关键词确定专家的表示向量，构建过程如下。

1）专家与关键词二分图 A U ：如果 keyword 是用户 user 使用过的关键词，或是 user 的研究方向，那么这个 keyword 就在 user u 的近邻集合 N(u) 中。假设 user-keyword 的出现频次为 f 则 Au=f，维度为 R M×n ，词频矩阵构建如下：

![image-20230131211626226](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131211626226.png)

归一化后得到：

![image-20230131211644699](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131211644699.png)

式中，d(u) 为用户 user 的出度，表示为：

![image-20230131211705035](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131211705035.png)

2）关键词与关键词二分图 A K ：如果关键词 i 与关键词 j 共同出现在同一篇论文，则 i 与 j 是邻居节点，关键词 j 在关键词 i 的近邻节点集合 N(i) 中，维度为 R n×n ，词共现矩阵构建如下：

![image-20230131211726652](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131211726652.png)

归一化后得到矩阵：

![image-20230131211743030](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131211743030.png)

式中，d 为二分图 A K 的度矩阵。

1.3 论文文本语义信息

论文的标题、摘要等包含丰富的语义信息，预训练语言模型 BERT 只需微调就能得到文本的语义表示：

![image-20230131211811561](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131211811561.png)

式中：p text 为论文的 p 标题或摘要文本信息；W 为权重矩阵，维度为 R 768 。将论文的**语义表示**与**关键词表示**融合在一起，使模型具备更丰富的论文信息。

1.4 图注意力网络 (GAT)

GCN 对邻居的聚合使用的是拉普拉斯矩阵，而GAT 则通过注意力机制实现对邻居的加权聚合。因此，GAT 不仅对于噪音邻居较为鲁棒，且注意力机制也赋予了模型一定的可解释性。

GAT 在计算相邻节点时引入注意力机制，关注权重较大的近邻节点。输入为关键词的初始嵌入向量：

![image-20230131211950755](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131211950755.png)

第 l 层 GAT 的输出为：

![image-20230131212002778](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131212002778.png)

GAT 先根据输入节点的特征向量集进行自注意力计算：

![image-20230131214533248](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131214533248.png)

为学习到二分图结构信息，使用 mask-attention的方式[22] ，仅将注意力分配到近邻节点集上：

![image-20230131214650179](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131214650179.png)

得到第 l 层图注意力网络的输出

![image-20230131214732077](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131214732077.png)

1.5 融合文本语义的图注意力网络 (BERT-GAT)

为每一层 GAT 引入文本的语义信息，在注意力阶段融入 BERT 的语义向量 v p ，如图 1 所示。假设论文 p 的关键词为 k，为引入语义信息，在注意力阶段加入文本语义向量的信息：

![image-20230131215111931](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131215111931.png)

为学习到二分图结构信息，使用 mask-attention 的方式，仅将注意力分配到近邻节点集上：

![image-20230131215056631](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131215056631.png)

至此，得到第 l 层图注意力网络的输出：

![image-20230131215232395](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131215232395.png)

若论文 p 的关键词为 p k ={k 1,k2 ,…,k x }，则论文 p的关键词表示为：

![image-20230131215301472](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131215301472.png)

x 为论文 p 关键词个数；r 为图注意力网络层数。

加入论文的文本表示，则论文 p 的最终表示为：

![image-20230131215354532](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131215354532.png)

1.6 专家的图卷积网络

专家 u 的研究兴趣经图卷积网络可以得到：

![image-20230131215413638](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131215413638.png)

专家 u 的最终表示为：

![image-20230131215429604](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131215429604.png)

1.7 损失函数

论文 p 与用户 u 的交互得分为：

![image-20230131215530210](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131215530210.png)

最终的损失函数为交叉熵损失函数和均方损失之和：

![image-20230131215620580](https://gitee.com/ning13445/picture/raw/master/picture/1/image-20230131215620580.png)